{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dad70e50-1a55-43d7-ad73-7662bd6821b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID SimilarCustomerID  SimilarityScore\n",
      "0      C0001             C0118         0.878134\n",
      "1      C0001             C0184         0.870396\n",
      "2      C0001             C0120         0.854405\n",
      "3      C0002             C0159         0.954488\n",
      "4      C0002             C0134         0.945575\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from datetime import datetime\n",
    "\n",
    "customers = pd.read_csv(r\"C:\\Users\\xdham\\Downloads\\Customers.csv\")\n",
    "products = pd.read_csv(r\"C:\\Users\\xdham\\Downloads\\Products.csv\")\n",
    "transactions = pd.read_csv(r\"C:\\Users\\xdham\\Downloads\\Transactions.csv\")\n",
    "\n",
    "merged_data = transactions.merge(customers, on='CustomerID').merge(products, on='ProductID')\n",
    "\n",
    "if 'Price' not in merged_data.columns:\n",
    "    merged_data['Price'] = merged_data['TotalValue'] / merged_data['Quantity']\n",
    "\n",
    "merged_data['SignupDate'] = pd.to_datetime(merged_data['SignupDate'])\n",
    "merged_data['TenureDays'] = (datetime.now() - merged_data['SignupDate']).dt.days\n",
    "\n",
    "customer_profiles = merged_data.groupby('CustomerID').agg({\n",
    "    'Region': 'first',\n",
    "    'TenureDays': 'first',\n",
    "    'Category': lambda x: ' '.join(x),\n",
    "    'Price': 'mean',\n",
    "    'TotalValue': 'sum',\n",
    "    'Quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "customer_profiles = pd.get_dummies(customer_profiles, columns=['Region'], drop_first=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Price', 'TotalValue', 'Quantity', 'TenureDays']\n",
    "customer_profiles[numerical_cols] = scaler.fit_transform(customer_profiles[numerical_cols])\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "category_features = vectorizer.fit_transform(customer_profiles['Category'])\n",
    "\n",
    "final_features = np.hstack([customer_profiles.drop(['CustomerID', 'Category'], axis=1).values, category_features.toarray()])\n",
    "\n",
    "similarity_matrix = cosine_similarity(final_features)\n",
    "\n",
    "def recommend_similar_customers(input_customer_id, n=3):\n",
    "    if input_customer_id not in customer_profiles['CustomerID'].values:\n",
    "        raise ValueError(f\"CustomerID {input_customer_id} not found.\")\n",
    "    \n",
    "    customer_idx = customer_profiles[customer_profiles['CustomerID'] == input_customer_id].index[0]\n",
    "    similarity_scores = similarity_matrix[customer_idx]\n",
    "    \n",
    "    similar_customers_idx = np.argsort(similarity_scores)[::-1][1:n+1]\n",
    "    similar_customers = customer_profiles.iloc[similar_customers_idx]\n",
    "    \n",
    "    similar_customers_map = [(row['CustomerID'], similarity_scores[idx]) for idx, row in similar_customers.iterrows()]\n",
    "    \n",
    "    return similar_customers_map\n",
    "\n",
    "lookalike_dict = {}\n",
    "for customer_id in [f'C{i:04d}' for i in range(1, 21)]:\n",
    "    try:\n",
    "        similar_customers = recommend_similar_customers(customer_id, n=3)\n",
    "        lookalike_dict[customer_id] = similar_customers\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "lookalike_data = []\n",
    "for customer_id, similar_customers in lookalike_dict.items():\n",
    "    for cust_id, score in similar_customers:\n",
    "        lookalike_data.append([customer_id, cust_id, score])\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_data, columns=['CustomerID', 'SimilarCustomerID', 'SimilarityScore'])\n",
    "\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "\n",
    "print(lookalike_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aeaa4e-6af9-4e76-92df-8b1ed285d5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
